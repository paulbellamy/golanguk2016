Advanced Patterns with io.ReadWriter

18 Aug 2016


Paul Bellamy
Software Engineer, Weaveworks
paul@weave.works
http://weave.works/
@pyrhho

* 

: Goal: After this talk you'll be able to say "That's not advanced, that's obvious!"

: There will be quite a lot of code
: We'll go through stuff fairly quick

.image weave.png 480 640

* 

: not this kind of readers.

.image kitten.jpg 480 640

* What's available in io, bufio, & ioutil?

: Simply put? Building blocks, and great examples

* What's available in io, bufio, & ioutil?

: ReadWriter is one of the most powerful abstractions available in Go.
: Simple
: Expressive
: Composable
: Interchangeable

  type ReadWriter interface {
        Read(p []byte) (n int, err error)
        Write(p []byte) (n int, err error)
  }

Tools for working with ReadWriters:

- io.Copy
- io.LimitReader
- io.TeeReader
- bufio.Scanner
- ioutil.Discard

Loads more!

* Composition

: Building our own abstractions around Readers is really easy
: And composing them
: Can be interchanged

* Composition

: Start with a basic reader
: Stream of numbers

: LimitedReader limits the amount of data returned to N bytes.
: After N bytes have been read, it returns io.EOF
: The signal for "no more data"

: Constructed with the LimitReader function

: LimitReader source is very readable
: A good example

: Wraps our number stream
: Still fulfills same interface
: Show Compression (gzip.NewReader on Stdout)
: MaxByteReader

.code -edit limit.go /START OMIT/,/END OMIT/

* Example 1 - HTTP Chunking

* Example 1 - HTTP Chunking

Let's transparently proxy a chunked HTTP in a stream.

: What does transparently mean?
: What does HTTP chunked encoding look like?

* Example 1 - HTTP Chunking

: Body is the interesting part here.
: Each chunk has a hex length, then carriage-return-linefeed
: E chunk is 14 characters long.
: Body ends with 0-length chunk
: Note the two trailers, Date, and Content-MD5
: Like headers, but *after* the body
: We want to verbatim forward the body
: We want to process the Trailers
: To verify the md5

Encoded:

  POST / HTTP/1.1
  Transfer-Encoding: chunked

  4\r\n
  Wiki\r\n
  5\r\n
  pedia\r\n
  E\r\n
   in\r\n
  \r\n
  chunks.\r\n
  0\r\n
  Date: Sun, 06 Nov 1994 08:49:37 GMT\r\n
  Content-MD5: 1B2M2Y8AsgTpgAmY7PhCfg==\r\n
  \r\n

Decoded Body:

  Wikipedia in

  chunks.

* Solution 1

Obvious solution with io.Copy

.image chunking1.svg

.code chunking1.go /START OMIT/,/END OMIT/

* Solution 1

Obvious solution with io.Copy

.image chunking1.svg

.code chunking1.go /START OMIT/,/END OMIT/

Problems:

- Won't let us process the Trailers separately
- We need to stop after the body

* Solution 2

: Dig around in httputil, and find httputil.ChunkedReader

Better solution with httputil.ChunkedReader

.image chunking2.svg

.code chunking2.go /START OMIT/,/END OMIT/

: Is great, and probably good enough for most of the time
: But, has some issues

* Solution 2

: Problems:
: Turns it into one continuous byte-stream
: Breaks the transparency of our proxy.

Better solution with httputil.ChunkedReader

.image chunking2.svg

Problems:

- Strips out the chunking data

  Wikipedia in
  
  chunks.

* Solution 3

: A correct solution. A bit dense
: Adds in a io.TeeReader, and ioutil.Discard.
: Every read from TeeReader writes the raw data to clientWriter, ChunkedReader to detect the end of the body
: io.Copy to "pull" the data through, but we don't care about the output
: Like a transistor

.image chunking3.svg

.code chunking3.go /START OMIT/,/END OMIT/

* Exercises For The Reader

: Answers:
: 1. Yes
: 2. Depends on number of copies

1. Could we implement this in a single reader?

2. Would that be more performant, or less?

* Example 2 - Multiplexing Subcommands

: Something a bit lighter

* Example 2 - Multiplexing Subcommands

: Running a bunch of subcommands
: Multiplexing the streaming output

Run subcommands, multiplex the output, give each a unique prefix.

Commands:

  echo "Hello,\nWorld!"
  make all
  git status

Output:

  [echo] Hello,
  [make] make: *** No rule to make target `all'.  Stop.
  [echo] World!
  [git] On branch master
  [git] Your branch is up-to-date with 'upstream/master'.
  [git] nothing to commit, working tree clean

* Example 2 - Multiplexing Subcommands

.image prefix.svg

* Example 2 - Multiplexing Subcommands

: Take list of commands
: Set up each one
: Create prefixingWriter for each (We'll implement that)
: Run them async

Starting up the commands

.code prefix.go /START USAGE OMIT/,/END USAGE OMIT/

* Example 2 - Multiplexing Subcommands

: Type signature

: Takes a prefix, and an output source
: Returns a new writer
: Any data written to this will have prefix on each line

Prefixing Writer

.code prefix.go /START DECL OMIT/,/END DECL OMIT/

* Example 2 - Multiplexing Subcommands

: A scanner turns streams of bytes into streams of tokens
: Default is split by line, others are utf-8 runes, words, or custom.
: This lets us iterate over the lines in a reader

: Let's look at input to see how it connects 

Splitting streams into sections with bufio.Scanner

  func prefixingWriter(prefix string, output io.Writer) io.Writer {
    input := ...

    // Iterate over each line
    scanner := bufio.NewScanner(input)
    for scanner.Scan() {

      // Write the prefix into the output
      fmt.Fprintf(output, "[%s] ", prefix)

      // Copy the line
      output.Write(scanner.Bytes())

      // Re-add a newline (scanner removes it)
      fmt.Fprint(output, "\n")

    }

    return input
  }

* Example 2 - Multiplexing Subcommands

: Input needs to connect a Writer to a Reader

What is `input` ?

- bufio.Scanner expects a io.Reader
- exec.Cmd expects a io.Writer

* Example 2 - Multiplexing Subcommands

: io.Pipe two synchronous halves, similar to a chan
: Write blocks on a read, Read blocks on a write

: Final implementation, Pipe to connect the reader and writer
: Scanner to tokenize into lines, Goroutine prefixing and merging

io.Pipe to the rescue

.image prefix3.svg

.code prefix.go /START IMPL OMIT/,/END IMPL OMIT/

* Exercises For The Reader

: Answers:
: 1. Yes, if output blocks indefinitely
: 2. Avoid using a goroutine. Use a WriteCloser, to guarantee cleanup
: 3. bytes.Buffer

1. Could this leak goroutines?

2. How could we avoid leaking goroutines?

3. What if we wanted to save the output until the process exited?
